{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "styletransfer_Anju.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amalphonse/60DaysUdacity/blob/master/styletransfer_Anju.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNzUsmev6UCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import resources\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import requests\n",
        "from torchvision import transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUsh2TdT6vYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the \"features\" portion of VGG19 (we will not need the \"classifier\" portion)\n",
        "vgg = models.vgg19(pretrained=True).features\n",
        "\n",
        "# freeze all VGG parameters since we're only optimizing the target image\n",
        "for param in vgg.parameters():\n",
        "    param.requires_grad_(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQIj5nri64R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# move the model to GPU, if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "vgg.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL-S_Xul7k6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(img_path, max_size=400, shape=None):\n",
        "    ''' Load in and transform an image, making sure the image\n",
        "       is <= 400 pixels in the x-y dims.'''\n",
        "    if \"http\" in img_path:\n",
        "        response = requests.get(img_path)\n",
        "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "    else:\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "    \n",
        "    # large images will slow down processing\n",
        "    if max(image.size) > max_size:\n",
        "        size = max_size\n",
        "    else:\n",
        "        size = max(image.size)\n",
        "    \n",
        "    if shape is not None:\n",
        "        size = shape\n",
        "        \n",
        "    in_transform = transforms.Compose([\n",
        "                        transforms.Resize(size),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.485, 0.456, 0.406), \n",
        "                                             (0.229, 0.224, 0.225))])\n",
        "\n",
        "    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n",
        "    image = in_transform(image)[:3,:,:].unsqueeze(0)\n",
        "    \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}